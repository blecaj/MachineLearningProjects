# MachineLearningProjects 
>** Explaining the predictions of any machine learning classifier**
### 1. Wine dataset, classification models comparison
 ----------------------------------------------
> Used different classifiers to compare, top most important features
  >>1. Train a Random Forest classifier on the data.
  >>2. Compute the feature importance score by permutating each feature.
  >>3. Re-train the model with only the top features.
  >>4. Check other classifiers for comparison.
> !# scikit-learn, numpy
>
>Laso classifier, Ridge classifier, Decision Tree classifier, Support Vector classifier SVM, & random Forest Classifer. 
>

### 2. fashion MNIST dataset, Shapely Values, Deep Learning model (CNN)
 ----------------------------------------------
>SHAP (SHapley Additive exPlanations). This procedure is derived from game theory and aims to >understand (or explain) the output of any machine learning model. 
>
>>1. Train a simple CNN on the fashion mnist dataset.
>>2. Compute the Shapley values for examples of each class.
>>3. Visualize these values and derive information from them.
> !# scikit-learn, numpy, Shap, tensorflow, matplotlib, Keras 
>
>CNN model, 5 layers model architecture   
